####################   lr    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.295     0.721     0.418       505
         1.0      0.953     0.765     0.849      3705

    accuracy                          0.760      4210
   macro avg      0.624     0.743     0.633      4210
weighted avg      0.874     0.760     0.797      4210

auc macro 0.814
confusion matrix
[[ 364  141]
 [ 871 2834]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.302     0.710     0.424       169
         1.0      0.951     0.776     0.855      1235

    accuracy                          0.768      1404
   macro avg      0.627     0.743     0.639      1404
weighted avg      0.873     0.768     0.803      1404

auc macro 0.820
confusion matrix
[[120  49]
 [277 958]]
Model rank: 1
Mean validation score: 0.641 (std: 0.005)
Parameters: {'model__C': 7, 'model__dual': True, 'model__max_iter': 70, 'model__penalty': 'l2', 'model__solver': 'liblinear', 'model__warm_start': True}

####################   lr  END   #########################
####################   svc    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.194     0.453     0.271       505
         1.0      0.909     0.743     0.817      3705

    accuracy                          0.708      4210
   macro avg      0.551     0.598     0.544      4210
weighted avg      0.823     0.708     0.752      4210

auc macro 0.633
confusion matrix
[[ 229  276]
 [ 953 2752]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.211     0.485     0.294       169
         1.0      0.914     0.752     0.825      1235

    accuracy                          0.720      1404
   macro avg      0.563     0.619     0.560      1404
weighted avg      0.830     0.720     0.761      1404

auc macro 0.648
confusion matrix
[[ 82  87]
 [306 929]]
Model rank: 1
Mean validation score: 0.631 (std: 0.014)
Parameters: {'model__C': 260, 'model__coef0': np.float64(0.4764319555781835), 'model__degree': 72, 'model__gamma': 'auto', 'model__kernel': 'rbf', 'model__max_iter': 1600}

####################   svc  END   #########################
####################   knn    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.634     0.481     0.547       505
         1.0      0.932     0.962     0.947      3705

    accuracy                          0.905      4210
   macro avg      0.783     0.722     0.747      4210
weighted avg      0.896     0.905     0.899      4210

auc macro 0.925
confusion matrix
[[ 243  262]
 [ 140 3565]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.405     0.278     0.330       169
         1.0      0.905     0.944     0.924      1235

    accuracy                          0.864      1404
   macro avg      0.655     0.611     0.627      1404
weighted avg      0.845     0.864     0.853      1404

auc macro 0.718
confusion matrix
[[  47  122]
 [  69 1166]]
Model rank: 1
Mean validation score: 0.603 (std: 0.004)
Parameters: {'model__algorithm': 'ball_tree', 'model__leaf_size': 38, 'model__n_neighbors': 4, 'model__weights': 'uniform'}

####################   knn  END   #########################
####################   rf    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.588     0.869     0.701       505
         1.0      0.981     0.917     0.948      3705

    accuracy                          0.911      4210
   macro avg      0.784     0.893     0.825      4210
weighted avg      0.934     0.911     0.918      4210

auc macro 0.968
confusion matrix
[[ 439   66]
 [ 308 3397]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.413     0.550     0.472       169
         1.0      0.936     0.893     0.914      1235

    accuracy                          0.852      1404
   macro avg      0.674     0.722     0.693      1404
weighted avg      0.873     0.852     0.861      1404

auc macro 0.828
confusion matrix
[[  93   76]
 [ 132 1103]]
Model rank: 1
Mean validation score: 0.666 (std: 0.003)
Parameters: {'model__class_weight': 'balanced', 'model__criterion': 'gini', 'model__max_features': 'log2', 'model__min_samples_leaf': 4, 'model__min_samples_split': 7, 'model__n_estimators': 133}

####################   rf  END   #########################
####################   adaboost    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.620     0.194     0.296       505
         1.0      0.900     0.984     0.940      3705

    accuracy                          0.889      4210
   macro avg      0.760     0.589     0.618      4210
weighted avg      0.866     0.889     0.863      4210

auc macro 0.821
confusion matrix
[[  98  407]
 [  60 3645]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.614     0.207     0.310       169
         1.0      0.901     0.982     0.940      1235

    accuracy                          0.889      1404
   macro avg      0.757     0.595     0.625      1404
weighted avg      0.866     0.889     0.864      1404

auc macro 0.823
confusion matrix
[[  35  134]
 [  22 1213]]
Model rank: 1
Mean validation score: 0.615 (std: 0.001)
Parameters: {'model__learning_rate': np.float64(1.0756954125989546), 'model__n_estimators': 89}

####################   adaboost  END   #########################
####################   nn    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.684     0.206     0.317       505
         1.0      0.901     0.987     0.942      3705

    accuracy                          0.893      4210
   macro avg      0.793     0.596     0.629      4210
weighted avg      0.875     0.893     0.867      4210

auc macro 0.825
confusion matrix
[[ 104  401]
 [  48 3657]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.702     0.237     0.354       169
         1.0      0.904     0.986     0.943      1235

    accuracy                          0.896      1404
   macro avg      0.803     0.611     0.649      1404
weighted avg      0.880     0.896     0.872      1404

auc macro 0.818
confusion matrix
[[  40  129]
 [  17 1218]]
Model rank: 1
Mean validation score: 0.650 (std: 0.003)
Parameters: {'model__alpha': np.float64(0.1022495542616435), 'model__early_stopping': True, 'model__hidden_layer_sizes': [191, 66], 'model__learning_rate': 'constant', 'model__learning_rate_init': np.float64(0.0035842921842781173), 'model__max_iter': 354, 'model__solver': 'adam'}

####################   nn  END   #########################
####################   gb    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.704     0.311     0.431       505
         1.0      0.913     0.982     0.946      3705

    accuracy                          0.902      4210
   macro avg      0.808     0.647     0.689      4210
weighted avg      0.888     0.902     0.884      4210

auc macro 0.864
confusion matrix
[[ 157  348]
 [  66 3639]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.584     0.266     0.366       169
         1.0      0.907     0.974     0.939      1235

    accuracy                          0.889      1404
   macro avg      0.745     0.620     0.652      1404
weighted avg      0.868     0.889     0.870      1404

auc macro 0.810
confusion matrix
[[  45  124]
 [  32 1203]]
Model rank: 1
Mean validation score: 0.638 (std: 0.014)
Parameters: {'model__learning_rate': np.float64(0.16252886807948705), 'model__max_depth': 5, 'model__max_features': 'log2', 'model__n_estimators': 35, 'model__subsample': 0.25}

####################   gb  END   #########################
####################   xgb    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.486     0.404     0.441       505
         1.0      0.921     0.942     0.931      3705

    accuracy                          0.877      4210
   macro avg      0.703     0.673     0.686      4210
weighted avg      0.868     0.877     0.872      4210

auc macro 0.835
confusion matrix
[[ 204  301]
 [ 216 3489]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.532     0.438     0.481       169
         1.0      0.925     0.947     0.936      1235

    accuracy                          0.886      1404
   macro avg      0.729     0.693     0.708      1404
weighted avg      0.878     0.886     0.881      1404

auc macro 0.826
confusion matrix
[[  74   95]
 [  65 1170]]
Model rank: 1
Mean validation score: 0.671 (std: 0.007)
Parameters: {'model__alpha': np.float64(0.011795231881217005), 'model__booster': 'dart', 'model__eta': np.float64(0.09630300090697876), 'model__gamma': np.float64(0.09423678607052631), 'model__lambda': np.float64(1.09766658342554), 'model__max_depth': 3, 'model__n_estimators': 38, 'model__scale_pos_weight': 0.4, 'model__subsample': 0.25}

####################   xgb  END   #########################
