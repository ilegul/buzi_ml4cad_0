####################   lr    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.337     0.709     0.457       505
         1.0      0.950     0.798     0.867      3494

    accuracy                          0.787      3999
   macro avg      0.643     0.754     0.662      3999
weighted avg      0.873     0.787     0.816      3999

auc macro 0.842
confusion matrix
[[ 358  147]
 [ 705 2789]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.323     0.604     0.421       169
         1.0      0.934     0.816     0.871      1165

    accuracy                          0.789      1334
   macro avg      0.628     0.710     0.646      1334
weighted avg      0.857     0.789     0.814      1334

auc macro 0.795
confusion matrix
[[102  67]
 [214 951]]
Model rank: 1
Mean validation score: 0.663 (std: 0.014)
Parameters: {'model__C': 8, 'model__dual': True, 'model__max_iter': 75, 'model__penalty': 'l2', 'model__solver': 'liblinear', 'model__warm_start': False}

####################   lr  END   #########################
####################   svc    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.260     0.588     0.361       505
         1.0      0.927     0.758     0.834      3494

    accuracy                          0.737      3999
   macro avg      0.594     0.673     0.597      3999
weighted avg      0.843     0.737     0.774      3999

auc macro 0.755
confusion matrix
[[ 297  208]
 [ 845 2649]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.259     0.538     0.349       169
         1.0      0.921     0.776     0.842      1165

    accuracy                          0.746      1334
   macro avg      0.590     0.657     0.596      1334
weighted avg      0.837     0.746     0.780      1334

auc macro 0.714
confusion matrix
[[ 91  78]
 [261 904]]
Model rank: 1
Mean validation score: 0.664 (std: 0.002)
Parameters: {'model__C': 281, 'model__coef0': np.float64(0.7056372943682397), 'model__degree': 40, 'model__gamma': 'auto', 'model__kernel': 'rbf', 'model__max_iter': 1600}

####################   svc  END   #########################
####################   knn    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.695     0.428     0.529       505
         1.0      0.922     0.973     0.947      3494

    accuracy                          0.904      3999
   macro avg      0.808     0.700     0.738      3999
weighted avg      0.893     0.904     0.894      3999

auc macro 0.913
confusion matrix
[[ 216  289]
 [  95 3399]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.423     0.195     0.267       169
         1.0      0.892     0.961     0.925      1165

    accuracy                          0.864      1334
   macro avg      0.657     0.578     0.596      1334
weighted avg      0.832     0.864     0.842      1334

auc macro 0.694
confusion matrix
[[  33  136]
 [  45 1120]]
Model rank: 1
Mean validation score: 0.636 (std: 0.004)
Parameters: {'model__algorithm': 'kd_tree', 'model__leaf_size': 13, 'model__n_neighbors': 6, 'model__weights': 'uniform'}

####################   knn  END   #########################
####################   rf    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.617     0.887     0.728       505
         1.0      0.983     0.920     0.950      3494

    accuracy                          0.916      3999
   macro avg      0.800     0.904     0.839      3999
weighted avg      0.936     0.916     0.922      3999

auc macro 0.970
confusion matrix
[[ 448   57]
 [ 278 3216]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.383     0.444     0.411       169
         1.0      0.917     0.896     0.907      1165

    accuracy                          0.839      1334
   macro avg      0.650     0.670     0.659      1334
weighted avg      0.850     0.839     0.844      1334

auc macro 0.788
confusion matrix
[[  75   94]
 [ 121 1044]]
Model rank: 1
Mean validation score: 0.690 (std: 0.005)
Parameters: {'model__class_weight': 'balanced_subsample', 'model__criterion': 'entropy', 'model__max_features': 'sqrt', 'model__min_samples_leaf': 4, 'model__min_samples_split': 3, 'model__n_estimators': 99}

####################   rf  END   #########################
####################   adaboost    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.578     0.220     0.319       505
         1.0      0.897     0.977     0.935      3494

    accuracy                          0.881      3999
   macro avg      0.737     0.598     0.627      3999
weighted avg      0.856     0.881     0.857      3999

auc macro 0.817
confusion matrix
[[ 111  394]
 [  81 3413]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.553     0.154     0.241       169
         1.0      0.889     0.982     0.933      1165

    accuracy                          0.877      1334
   macro avg      0.721     0.568     0.587      1334
weighted avg      0.846     0.877     0.845      1334

auc macro 0.779
confusion matrix
[[  26  143]
 [  21 1144]]
Model rank: 1
Mean validation score: 0.652 (std: 0.002)
Parameters: {'model__learning_rate': np.float64(1.1973518258794984), 'model__n_estimators': 11}

####################   adaboost  END   #########################
####################   nn    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.634     0.230     0.337       505
         1.0      0.898     0.981     0.938      3494

    accuracy                          0.886      3999
   macro avg      0.766     0.605     0.637      3999
weighted avg      0.865     0.886     0.862      3999

auc macro 0.848
confusion matrix
[[ 116  389]
 [  67 3427]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.600     0.160     0.252       169
         1.0      0.890     0.985     0.935      1165

    accuracy                          0.880      1334
   macro avg      0.745     0.572     0.594      1334
weighted avg      0.853     0.880     0.848      1334

auc macro 0.799
confusion matrix
[[  27  142]
 [  18 1147]]
Model rank: 1
Mean validation score: 0.676 (std: 0.007)
Parameters: {'model__alpha': np.float64(0.0410001277549491), 'model__early_stopping': True, 'model__hidden_layer_sizes': [168, 86], 'model__learning_rate': 'constant', 'model__learning_rate_init': np.float64(0.0029530341619509346), 'model__max_iter': 332, 'model__solver': 'adam'}

####################   nn  END   #########################
####################   gb    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.679     0.327     0.441       505
         1.0      0.909     0.978     0.942      3494

    accuracy                          0.895      3999
   macro avg      0.794     0.652     0.692      3999
weighted avg      0.880     0.895     0.879      3999

auc macro 0.860
confusion matrix
[[ 165  340]
 [  78 3416]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.547     0.207     0.300       169
         1.0      0.894     0.975     0.933      1165

    accuracy                          0.878      1334
   macro avg      0.721     0.591     0.617      1334
weighted avg      0.850     0.878     0.853      1334

auc macro 0.801
confusion matrix
[[  35  134]
 [  29 1136]]
Model rank: 1
Mean validation score: 0.662 (std: 0.003)
Parameters: {'model__learning_rate': np.float64(0.19326918007730073), 'model__max_depth': 4, 'model__max_features': 'log2', 'model__n_estimators': 23, 'model__subsample': 0.25}

####################   gb  END   #########################
####################   lr    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.338     0.735     0.463       505
         1.0      0.954     0.792     0.866      3494

    accuracy                          0.785      3999
   macro avg      0.646     0.763     0.664      3999
weighted avg      0.876     0.785     0.815      3999

auc macro 0.833
confusion matrix
[[ 371  134]
 [ 726 2768]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.298     0.657     0.410       169
         1.0      0.940     0.775     0.849      1165

    accuracy                          0.760      1334
   macro avg      0.619     0.716     0.630      1334
weighted avg      0.858     0.760     0.794      1334

auc macro 0.798
confusion matrix
[[111  58]
 [262 903]]
Model rank: 1
Mean validation score: 0.654 (std: 0.002)
Parameters: {'model__C': 9, 'model__dual': True, 'model__max_iter': 66, 'model__penalty': 'l2', 'model__solver': 'liblinear', 'model__warm_start': True}

####################   lr  END   #########################
####################   lr    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.324     0.709     0.445       505
         1.0      0.949     0.786     0.860      3494

    accuracy                          0.777      3999
   macro avg      0.637     0.748     0.653      3999
weighted avg      0.870     0.777     0.808      3999

auc macro 0.829
confusion matrix
[[ 358  147]
 [ 746 2748]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.317     0.704     0.438       169
         1.0      0.948     0.780     0.856      1165

    accuracy                          0.771      1334
   macro avg      0.633     0.742     0.647      1334
weighted avg      0.868     0.771     0.803      1334

auc macro 0.826
confusion matrix
[[119  50]
 [256 909]]
Model rank: 1
Mean validation score: 0.645 (std: 0.002)
Parameters: {'model__C': 7, 'model__dual': True, 'model__max_iter': 70, 'model__penalty': 'l2', 'model__solver': 'liblinear', 'model__warm_start': True}

####################   lr  END   #########################
####################   svc    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.182     0.499     0.267       505
         1.0      0.903     0.675     0.773      3494

    accuracy                          0.653      3999
   macro avg      0.542     0.587     0.520      3999
weighted avg      0.812     0.653     0.709      3999

auc macro 0.595
confusion matrix
[[ 252  253]
 [1134 2360]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.190     0.503     0.276       169
         1.0      0.905     0.688     0.782      1165

    accuracy                          0.665      1334
   macro avg      0.547     0.596     0.529      1334
weighted avg      0.815     0.665     0.718      1334

auc macro 0.595
confusion matrix
[[ 85  84]
 [363 802]]
Model rank: 1
Mean validation score: 0.647 (std: 0.012)
Parameters: {'model__C': 244, 'model__coef0': np.float64(0.41652139288784373), 'model__degree': 159, 'model__gamma': 'auto', 'model__kernel': 'rbf', 'model__max_iter': 1600}

####################   svc  END   #########################
####################   knn    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.649     0.366     0.468       505
         1.0      0.914     0.971     0.942      3494

    accuracy                          0.895      3999
   macro avg      0.781     0.669     0.705      3999
weighted avg      0.880     0.895     0.882      3999

auc macro 0.904
confusion matrix
[[ 185  320]
 [ 100 3394]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.421     0.237     0.303       169
         1.0      0.896     0.953     0.923      1165

    accuracy                          0.862      1334
   macro avg      0.658     0.595     0.613      1334
weighted avg      0.836     0.862     0.845      1334

auc macro 0.728
confusion matrix
[[  40  129]
 [  55 1110]]
Model rank: 1
Mean validation score: 0.626 (std: 0.004)
Parameters: {'model__algorithm': 'kd_tree', 'model__leaf_size': 21, 'model__n_neighbors': 6, 'model__weights': 'uniform'}

####################   knn  END   #########################
####################   rf    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.692     0.881     0.775       505
         1.0      0.982     0.943     0.962      3494

    accuracy                          0.935      3999
   macro avg      0.837     0.912     0.869      3999
weighted avg      0.945     0.935     0.939      3999

auc macro 0.978
confusion matrix
[[ 445   60]
 [ 198 3296]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.431     0.479     0.454       169
         1.0      0.923     0.908     0.916      1165

    accuracy                          0.854      1334
   macro avg      0.677     0.694     0.685      1334
weighted avg      0.861     0.854     0.857      1334

auc macro 0.804
confusion matrix
[[  81   88]
 [ 107 1058]]
Model rank: 1
Mean validation score: 0.676 (std: 0.009)
Parameters: {'model__class_weight': 'balanced', 'model__criterion': 'entropy', 'model__max_features': 'sqrt', 'model__min_samples_leaf': 3, 'model__min_samples_split': 7, 'model__n_estimators': 42}

####################   rf  END   #########################
####################   adaboost    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.629     0.212     0.317       505
         1.0      0.896     0.982     0.937      3494

    accuracy                          0.885      3999
   macro avg      0.763     0.597     0.627      3999
weighted avg      0.862     0.885     0.859      3999

auc macro 0.826
confusion matrix
[[ 107  398]
 [  63 3431]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.562     0.160     0.249       169
         1.0      0.890     0.982     0.933      1165

    accuracy                          0.878      1334
   macro avg      0.726     0.571     0.591      1334
weighted avg      0.848     0.878     0.847      1334

auc macro 0.812
confusion matrix
[[  27  142]
 [  21 1144]]
Model rank: 1
Mean validation score: 0.646 (std: 0.008)
Parameters: {'model__learning_rate': np.float64(1.1427898542388701), 'model__n_estimators': 55}

####################   adaboost  END   #########################
####################   nn    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.758     0.198     0.314       505
         1.0      0.895     0.991     0.941      3494

    accuracy                          0.891      3999
   macro avg      0.826     0.594     0.627      3999
weighted avg      0.878     0.891     0.861      3999

auc macro 0.847
confusion matrix
[[ 100  405]
 [  32 3462]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.568     0.148     0.235       169
         1.0      0.888     0.984     0.934      1165

    accuracy                          0.878      1334
   macro avg      0.728     0.566     0.584      1334
weighted avg      0.848     0.878     0.845      1334

auc macro 0.828
confusion matrix
[[  25  144]
 [  19 1146]]
Model rank: 1
Mean validation score: 0.657 (std: 0.000)
Parameters: {'model__alpha': np.float64(0.1336646463618394), 'model__early_stopping': True, 'model__hidden_layer_sizes': [157, 79], 'model__learning_rate': 'constant', 'model__learning_rate_init': np.float64(0.004766983240019507), 'model__max_iter': 357, 'model__solver': 'adam'}

####################   nn  END   #########################
####################   gb    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.725     0.303     0.427       505
         1.0      0.907     0.983     0.944      3494

    accuracy                          0.897      3999
   macro avg      0.816     0.643     0.686      3999
weighted avg      0.884     0.897     0.878      3999

auc macro 0.853
confusion matrix
[[ 153  352]
 [  58 3436]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.583     0.207     0.306       169
         1.0      0.895     0.979     0.935      1165

    accuracy                          0.881      1334
   macro avg      0.739     0.593     0.620      1334
weighted avg      0.855     0.881     0.855      1334

auc macro 0.821
confusion matrix
[[  35  134]
 [  25 1140]]
Model rank: 1
Mean validation score: 0.660 (std: 0.006)
Parameters: {'model__learning_rate': np.float64(0.1399617820351129), 'model__max_depth': 3, 'model__max_features': 'sqrt', 'model__n_estimators': 73, 'model__subsample': 0.5}

####################   gb  END   #########################
####################   xgb    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.501     0.487     0.494       505
         1.0      0.926     0.930     0.928      3494

    accuracy                          0.874      3999
   macro avg      0.714     0.709     0.711      3999
weighted avg      0.872     0.874     0.873      3999

auc macro 0.837
confusion matrix
[[ 246  259]
 [ 245 3249]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.389     0.385     0.387       169
         1.0      0.911     0.912     0.912      1165

    accuracy                          0.846      1334
   macro avg      0.650     0.649     0.649      1334
weighted avg      0.845     0.846     0.845      1334

auc macro 0.822
confusion matrix
[[  65  104]
 [ 102 1063]]
Model rank: 1
Mean validation score: 0.690 (std: 0.002)
Parameters: {'model__alpha': np.float64(0.4052131498117949), 'model__booster': 'gbtree', 'model__eta': np.float64(0.11848335311853793), 'model__gamma': np.float64(0.07700234752641917), 'model__lambda': np.float64(0.8943535808423686), 'model__max_depth': 2, 'model__n_estimators': 44, 'model__scale_pos_weight': 0.4, 'model__subsample': 0.5}

####################   xgb  END   #########################
