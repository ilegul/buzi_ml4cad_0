####################   svc    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.853     0.742     0.794      1262
         1.0      0.772     0.872     0.819      1262

    accuracy                          0.807      2524
   macro avg      0.812     0.807     0.806      2524
weighted avg      0.812     0.807     0.806      2524

auc macro 0.901
confusion matrix
[[ 936  326]
 [ 161 1101]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.351     0.592     0.441       169
         1.0      0.934     0.841     0.885      1165

    accuracy                          0.810      1334
   macro avg      0.643     0.716     0.663      1334
weighted avg      0.860     0.810     0.829      1334

auc macro 0.783
confusion matrix
[[100  69]
 [185 980]]
Parameters: {'memory': None, 'steps': [('preprocess', ColumnTransformer(remainder='passthrough',
                  transformers=[('stand', StandardScaler(), [1, 16, 8])],
                  verbose_feature_names_out=False)), ('model', SVC(C=244, class_weight='balanced', coef0=np.float64(0.41652139288784373),
    degree=159, gamma='auto', max_iter=1600, probability=True))], 'transform_input': None, 'verbose': False, 'preprocess': ColumnTransformer(remainder='passthrough',
                  transformers=[('stand', StandardScaler(), [1, 16, 8])],
                  verbose_feature_names_out=False), 'model': SVC(C=244, class_weight='balanced', coef0=np.float64(0.41652139288784373),
    degree=159, gamma='auto', max_iter=1600, probability=True), 'preprocess__force_int_remainder_cols': 'deprecated', 'preprocess__n_jobs': None, 'preprocess__remainder': 'passthrough', 'preprocess__sparse_threshold': 0.3, 'preprocess__transformer_weights': None, 'preprocess__transformers': [('stand', StandardScaler(), [1, 16, 8])], 'preprocess__verbose': False, 'preprocess__verbose_feature_names_out': False, 'preprocess__stand': StandardScaler(), 'preprocess__stand__copy': True, 'preprocess__stand__with_mean': True, 'preprocess__stand__with_std': True, 'model__C': 244, 'model__break_ties': False, 'model__cache_size': 200, 'model__class_weight': 'balanced', 'model__coef0': np.float64(0.41652139288784373), 'model__decision_function_shape': 'ovr', 'model__degree': 159, 'model__gamma': 'auto', 'model__kernel': 'rbf', 'model__max_iter': 1600, 'model__probability': True, 'model__random_state': None, 'model__shrinking': True, 'model__tol': 0.001, 'model__verbose': False}
####################   svc  END   #########################
####################   rf    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.960     0.905     0.931      1262
         1.0      0.910     0.962     0.935      1262

    accuracy                          0.933      2524
   macro avg      0.935     0.933     0.933      2524
weighted avg      0.935     0.933     0.933      2524

auc macro 0.985
confusion matrix
[[1142  120]
 [  48 1214]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.397     0.527     0.453       169
         1.0      0.928     0.884     0.905      1165

    accuracy                          0.839      1334
   macro avg      0.663     0.705     0.679      1334
weighted avg      0.861     0.839     0.848      1334

auc macro 0.816
confusion matrix
[[  89   80]
 [ 135 1030]]
Parameters: {'memory': None, 'steps': [('preprocess', ColumnTransformer(remainder='passthrough',
                  transformers=[('stand', StandardScaler(), [1, 16, 8])],
                  verbose_feature_names_out=False)), ('model', RandomForestClassifier(class_weight='balanced', criterion='entropy',
                       min_samples_leaf=3, min_samples_split=7,
                       n_estimators=42))], 'transform_input': None, 'verbose': False, 'preprocess': ColumnTransformer(remainder='passthrough',
                  transformers=[('stand', StandardScaler(), [1, 16, 8])],
                  verbose_feature_names_out=False), 'model': RandomForestClassifier(class_weight='balanced', criterion='entropy',
                       min_samples_leaf=3, min_samples_split=7,
                       n_estimators=42), 'preprocess__force_int_remainder_cols': 'deprecated', 'preprocess__n_jobs': None, 'preprocess__remainder': 'passthrough', 'preprocess__sparse_threshold': 0.3, 'preprocess__transformer_weights': None, 'preprocess__transformers': [('stand', StandardScaler(), [1, 16, 8])], 'preprocess__verbose': False, 'preprocess__verbose_feature_names_out': False, 'preprocess__stand': StandardScaler(), 'preprocess__stand__copy': True, 'preprocess__stand__with_mean': True, 'preprocess__stand__with_std': True, 'model__bootstrap': True, 'model__ccp_alpha': 0.0, 'model__class_weight': 'balanced', 'model__criterion': 'entropy', 'model__max_depth': None, 'model__max_features': 'sqrt', 'model__max_leaf_nodes': None, 'model__max_samples': None, 'model__min_impurity_decrease': 0.0, 'model__min_samples_leaf': 3, 'model__min_samples_split': 7, 'model__min_weight_fraction_leaf': 0.0, 'model__monotonic_cst': None, 'model__n_estimators': 42, 'model__n_jobs': None, 'model__oob_score': False, 'model__random_state': None, 'model__verbose': 0, 'model__warm_start': False}
####################   rf  END   #########################
####################   gb    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.906     0.877     0.891      2020
         1.0      0.881     0.909     0.895      2020

    accuracy                          0.893      4040
   macro avg      0.893     0.893     0.893      4040
weighted avg      0.893     0.893     0.893      4040

auc macro 0.958
confusion matrix
[[1772  248]
 [ 184 1836]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.450     0.503     0.475       169
         1.0      0.927     0.911     0.919      1165

    accuracy                          0.859      1334
   macro avg      0.688     0.707     0.697      1334
weighted avg      0.866     0.859     0.862      1334

auc macro 0.827
confusion matrix
[[  85   84]
 [ 104 1061]]
Parameters: {'memory': None, 'steps': [('preprocess', ColumnTransformer(remainder='passthrough',
                  transformers=[('stand', StandardScaler(), [1, 16, 8])],
                  verbose_feature_names_out=False)), ('model', GradientBoostingClassifier(learning_rate=np.float64(0.1399617820351129),
                           max_features='sqrt', n_estimators=73, subsample=0.5))], 'transform_input': None, 'verbose': False, 'preprocess': ColumnTransformer(remainder='passthrough',
                  transformers=[('stand', StandardScaler(), [1, 16, 8])],
                  verbose_feature_names_out=False), 'model': GradientBoostingClassifier(learning_rate=np.float64(0.1399617820351129),
                           max_features='sqrt', n_estimators=73, subsample=0.5), 'preprocess__force_int_remainder_cols': 'deprecated', 'preprocess__n_jobs': None, 'preprocess__remainder': 'passthrough', 'preprocess__sparse_threshold': 0.3, 'preprocess__transformer_weights': None, 'preprocess__transformers': [('stand', StandardScaler(), [1, 16, 8])], 'preprocess__verbose': False, 'preprocess__verbose_feature_names_out': False, 'preprocess__stand': StandardScaler(), 'preprocess__stand__copy': True, 'preprocess__stand__with_mean': True, 'preprocess__stand__with_std': True, 'model__ccp_alpha': 0.0, 'model__criterion': 'friedman_mse', 'model__init': None, 'model__learning_rate': np.float64(0.1399617820351129), 'model__loss': 'log_loss', 'model__max_depth': 3, 'model__max_features': 'sqrt', 'model__max_leaf_nodes': None, 'model__min_impurity_decrease': 0.0, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__min_weight_fraction_leaf': 0.0, 'model__n_estimators': 73, 'model__n_iter_no_change': None, 'model__random_state': None, 'model__subsample': 0.5, 'model__tol': 0.0001, 'model__validation_fraction': 0.1, 'model__verbose': 0, 'model__warm_start': False}
####################   gb  END   #########################
