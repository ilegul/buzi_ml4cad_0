####################   lr    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.426     0.523     0.470       505
         1.0      0.933     0.904     0.918      3705

    accuracy                          0.858      4210
   macro avg      0.680     0.713     0.694      4210
weighted avg      0.872     0.858     0.865      4210

auc macro 0.834
confusion matrix
[[ 264  241]
 [ 355 3350]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.377     0.462     0.415       169
         1.0      0.924     0.896     0.910      1235

    accuracy                          0.843      1404
   macro avg      0.650     0.679     0.662      1404
weighted avg      0.858     0.843     0.850      1404

auc macro 0.814
confusion matrix
[[  78   91]
 [ 129 1106]]
Model rank: 1
Mean validation score: 0.688 (std: 0.012)
Parameters: {'model__C': 9, 'model__dual': True, 'model__max_iter': 247, 'model__penalty': 'l2', 'model__solver': 'liblinear', 'model__warm_start': True}

####################   lr  END   #########################
####################   svc    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.173     0.511     0.258       505
         1.0      0.909     0.666     0.769      3705

    accuracy                          0.648      4210
   macro avg      0.541     0.589     0.513      4210
weighted avg      0.821     0.648     0.708      4210

auc macro 0.623
confusion matrix
[[ 258  247]
 [1237 2468]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.169     0.503     0.253       169
         1.0      0.907     0.661     0.764      1235

    accuracy                          0.642      1404
   macro avg      0.538     0.582     0.509      1404
weighted avg      0.818     0.642     0.703      1404

auc macro 0.613
confusion matrix
[[ 85  84]
 [419 816]]
Model rank: 1
Mean validation score: 0.660 (std: 0.011)
Parameters: {'model__C': 103, 'model__coef0': np.float64(0.37943689926772184), 'model__degree': 84, 'model__gamma': 'scale', 'model__kernel': 'rbf', 'model__max_iter': 1200}

####################   svc  END   #########################
####################   knn    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.651     0.503     0.568       505
         1.0      0.934     0.963     0.949      3705

    accuracy                          0.908      4210
   macro avg      0.793     0.733     0.758      4210
weighted avg      0.900     0.908     0.903      4210

auc macro 0.934
confusion matrix
[[ 254  251]
 [ 136 3569]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.378     0.219     0.277       169
         1.0      0.899     0.951     0.924      1235

    accuracy                          0.863      1404
   macro avg      0.638     0.585     0.601      1404
weighted avg      0.836     0.863     0.846      1404

auc macro 0.667
confusion matrix
[[  37  132]
 [  61 1174]]
Model rank: 1
Mean validation score: 0.623 (std: 0.001)
Parameters: {'model__algorithm': 'ball_tree', 'model__leaf_size': 11, 'model__n_neighbors': 4, 'model__weights': 'uniform'}

####################   knn  END   #########################
####################   rf    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.770     0.915     0.836       505
         1.0      0.988     0.963     0.975      3705

    accuracy                          0.957      4210
   macro avg      0.879     0.939     0.906      4210
weighted avg      0.962     0.957     0.959      4210

auc macro 0.991
confusion matrix
[[ 462   43]
 [ 138 3567]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.424     0.426     0.425       169
         1.0      0.921     0.921     0.921      1235

    accuracy                          0.861      1404
   macro avg      0.672     0.673     0.673      1404
weighted avg      0.861     0.861     0.861      1404

auc macro 0.812
confusion matrix
[[  72   97]
 [  98 1137]]
Model rank: 1
Mean validation score: 0.697 (std: 0.006)
Parameters: {'model__class_weight': 'balanced_subsample', 'model__criterion': 'gini', 'model__max_features': 'sqrt', 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 73}

####################   rf  END   #########################
####################   adaboost    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.575     0.257     0.356       505
         1.0      0.906     0.974     0.939      3705

    accuracy                          0.888      4210
   macro avg      0.741     0.616     0.647      4210
weighted avg      0.866     0.888     0.869      4210

auc macro 0.843
confusion matrix
[[ 130  375]
 [  96 3609]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.532     0.249     0.339       169
         1.0      0.904     0.970     0.936      1235

    accuracy                          0.883      1404
   macro avg      0.718     0.609     0.637      1404
weighted avg      0.859     0.883     0.864      1404

auc macro 0.808
confusion matrix
[[  42  127]
 [  37 1198]]
Model rank: 1
Mean validation score: 0.658 (std: 0.003)
Parameters: {'model__learning_rate': np.float64(1.1405706215541453), 'model__n_estimators': 93}

####################   adaboost  END   #########################
####################   nn    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.644     0.186     0.289       505
         1.0      0.899     0.986     0.940      3705

    accuracy                          0.890      4210
   macro avg      0.771     0.586     0.615      4210
weighted avg      0.868     0.890     0.862      4210

auc macro 0.811
confusion matrix
[[  94  411]
 [  52 3653]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.540     0.160     0.247       169
         1.0      0.895     0.981     0.936      1235

    accuracy                          0.882      1404
   macro avg      0.718     0.571     0.591      1404
weighted avg      0.852     0.882     0.853      1404

auc macro 0.801
confusion matrix
[[  27  142]
 [  23 1212]]
Model rank: 1
Mean validation score: 0.676 (std: 0.007)
Parameters: {'model__alpha': np.float64(0.26474653699729145), 'model__early_stopping': True, 'model__hidden_layer_sizes': [191, 66], 'model__learning_rate': 'adaptive', 'model__learning_rate_init': np.float64(0.002088541355056933), 'model__max_iter': 409, 'model__solver': 'adam'}

####################   nn  END   #########################
####################   gb    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.943     0.556     0.700       505
         1.0      0.943     0.995     0.968      3705

    accuracy                          0.943      4210
   macro avg      0.943     0.776     0.834      4210
weighted avg      0.943     0.943     0.936      4210

auc macro 0.946
confusion matrix
[[ 281  224]
 [  17 3688]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.541     0.272     0.362       169
         1.0      0.907     0.968     0.937      1235

    accuracy                          0.885      1404
   macro avg      0.724     0.620     0.649      1404
weighted avg      0.863     0.885     0.867      1404

auc macro 0.796
confusion matrix
[[  46  123]
 [  39 1196]]
Model rank: 1
Mean validation score: 0.668 (std: 0.015)
Parameters: {'model__learning_rate': np.float64(0.22619602535245456), 'model__max_depth': 4, 'model__max_features': 'sqrt', 'model__n_estimators': 88, 'model__subsample': 0.75}

####################   gb  END   #########################
####################   xgb    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.551     0.543     0.547       505
         1.0      0.938     0.940     0.939      3705

    accuracy                          0.892      4210
   macro avg      0.745     0.741     0.743      4210
weighted avg      0.891     0.892     0.892      4210

auc macro 0.882
confusion matrix
[[ 274  231]
 [ 223 3482]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.429     0.414     0.422       169
         1.0      0.920     0.925     0.922      1235

    accuracy                          0.863      1404
   macro avg      0.675     0.669     0.672      1404
weighted avg      0.861     0.863     0.862      1404

auc macro 0.823
confusion matrix
[[  70   99]
 [  93 1142]]
Model rank: 1
Mean validation score: 0.708 (std: 0.003)
Parameters: {'model__alpha': np.float64(0.2723232016732956), 'model__booster': 'gbtree', 'model__eta': np.float64(0.3185020243281191), 'model__gamma': np.float64(0.08575311377005734), 'model__lambda': np.float64(1.5781436822703223), 'model__max_depth': 3, 'model__n_estimators': 18, 'model__scale_pos_weight': 0.4, 'model__subsample': 1}

####################   xgb  END   #########################
